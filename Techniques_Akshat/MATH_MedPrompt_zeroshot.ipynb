{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f35d1af-56de-4bd2-b45c-3a8d8f71e62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import json \n",
    "import regex\n",
    "import random\n",
    "import pickle \n",
    "import re\n",
    "import sys\n",
    "import numpy as np\n",
    "from tqdm import tqdm, trange\n",
    "import json\n",
    "import pandas as pd\n",
    "import time\n",
    "from math import *\n",
    "import sys\n",
    "import openai\n",
    "from openai.error import RateLimitError\n",
    "from func_timeout import func_timeout, FunctionTimedOut\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251612d1-2525-495f-8c76-03c5d8ea96fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MATH_MedPrompt:\n",
    "    def __init__(self, base, version, key, lm, method, backend_args, quota_args, **kwargs):\n",
    "        self.lm = lm\n",
    "        self.method = method  # step\n",
    "        self.backend = backend_args['name']  # openai\n",
    "        \n",
    "        if self.backend == 'openai':\n",
    "            openai.api_type = \"azure\"\n",
    "            openai.api_base = base\n",
    "            openai.api_version = version\n",
    "            openai.api_key = key\n",
    "    \n",
    "        self.top_p = backend_args['top_p']\n",
    "        self.temp = backend_args['temp']\n",
    "        self.max_token = backend_args['max_token']\n",
    "        self.presence_penalty = backend_args['presence_penalty']        \n",
    "        \n",
    "        self.max_iter_per_instance = quota_args['max_iter_per_instance']\n",
    "\n",
    "        \n",
    "        self.history = []\n",
    "        self.strategy = None\n",
    "\n",
    "        # openai api\n",
    "        self.n_prompt_token = 0\n",
    "        self.n_sample_token = 0\n",
    "        self.messages = []\n",
    "    \n",
    "    def call_openai_api(self, messages, stop, lm=None, top_p=None):\n",
    "        n_try = 10\n",
    "        while n_try > 0:\n",
    "            try:\n",
    "                time.sleep(1)\n",
    "                response = func_timeout(90, \n",
    "                    openai.ChatCompletion.create,\n",
    "                    kwargs={\n",
    "                        \"engine\": self.lm if lm is None else lm,\n",
    "                        \"messages\": messages,\n",
    "                        \"top_p\": self.top_p if top_p is None else top_p,\n",
    "                        \"temperature\": self.temp,\n",
    "                        \"max_tokens\": self.max_token,\n",
    "                        \"presence_penalty\": self.presence_penalty,\n",
    "                        \"stop\": stop,\n",
    "                    }\n",
    "                )\n",
    "                break\n",
    "            except FunctionTimedOut:\n",
    "                print('[LOG] OpenAI API call timeout')\n",
    "                n_try -= 1\n",
    "                if n_try == 0:\n",
    "                    raise Exception('Failed 10 retries.')\n",
    "                continue\n",
    "            except Exception as e:\n",
    "                #print('[LOG]', e)\n",
    "                time.sleep(15)\n",
    "                n_try -= 1\n",
    "                if n_try == 0:\n",
    "                    raise Exception('Failed 10 retries.')\n",
    "                continue\n",
    "        return response\n",
    "    \n",
    "    def call_lm(self, prompt, add_response=True, stop=None, lm=None, top_p=None):\n",
    "        \n",
    "        self.messages.append({'role': 'user', 'content': prompt})\n",
    "        #self.messages = [{'role': 'user', 'content': prompt}]\n",
    "        response = self.call_openai_api(self.messages, stop, lm=lm, top_p=top_p)\n",
    "        if add_response: self.messages.append(response['choices'][0]['message'])\n",
    "        self.n_prompt_token += response['usage']['prompt_tokens']\n",
    "        self.n_sample_token += response['usage']['completion_tokens']\n",
    "        return response['choices'][0]['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0dd34ec-b766-4fbc-9759-3f5a11d45ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## For generating Chain of thought response, to be used later\n",
    "def get_CoT_prompt(problem):\n",
    "    return \"Problem - \"+problem+\"\\n\\nSolution - Let's think step by step: \"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bcabffb9-63d5-43f6-aeff-a7b93fb6c1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_answer_prompt(prompt_cot):\n",
    "    return prompt_cot+\"\\n\\nGive the final answer in the format, #Final answer : <Final_Answer>(only answer value NO units and no other text)#. Therefore the final answer is:\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad911992-044c-4614-8d58-38f1011e99c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='argparse')\n",
    "parser.add_argument('--start', type=int, default=0,\n",
    "                    help=\"Starting index\")\n",
    "parser.add_argument('--end', type=int, default=12500,\n",
    "                    help=\"Ending index\")\n",
    "parser.add_argument('--base', type=str, default=12500,\n",
    "                    help=\"api_base\")\n",
    "parser.add_argument('--version', type=str, default=12500,\n",
    "                    help=\"api_version\")\n",
    "parser.add_argument('--key', type=str, default=12500,\n",
    "                    help=\"api_key\")\n",
    "\n",
    "args = parser.parse_args()\n",
    "start = int(args.start)\n",
    "end = int(args.end)\n",
    "base = args.base\n",
    "version = args.version\n",
    "key = args.key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce2df8d-adb8-43af-a0db-6e22235746f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "backend_args = {\n",
    "        'name': \"openai\",\n",
    "        'top_p': 1,\n",
    "        'temp': 0,\n",
    "        'max_token': 3000,\n",
    "        'presence_penalty': 1.5,\n",
    "    }\n",
    "\n",
    "quota_args = {\n",
    "        'sleep_minutes': 1,\n",
    "        'max_iter_per_instance': 4\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ee0b0a-0b71-433d-9314-d75b5b8796cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Using the already generated zeroshot-CoT responses\n",
    "with open(\"../gpt4_zeroshot-CoT_pred.json\") as f:\n",
    "    data = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7b8d72-4afe-42b5-95b0-37aeb1606866",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_json = []\n",
    "for i in trange(start, end):\n",
    "    math = MATH_MedPrompt(base, version, key, \"gpt-4-turbo\", 'step', backend_args, quota_args)\n",
    "    problem = data[i]['problem']\n",
    "    cot = data[i]['pred']\n",
    "    prompt_cot = \"Problem - \"+problem+\"\\n\\nSolution - Let's think step by step : \\n\"+cot\n",
    "    final_prompt = final_answer_prompt(prompt_cot)\n",
    "    res_final = math.call_lm(final_prompt)\n",
    "    final_json.append({\n",
    "        \"index\": i,\n",
    "        \"problem\": data[i]['problem'],\n",
    "        \"CoT\" : data[i]['pred'],\n",
    "        \"final_answer\" : res_final.split(\":\")[-1][:-1],\n",
    "        \"label\" : data[i]['label']})\n",
    "    \n",
    "    if i%1==0:\n",
    "        with open(f\"./COT_Pred/gpt4_{start}_{end}_cot_pred.json\", 'w') as f:\n",
    "            json.dump(final_json, f)\n",
    "\n",
    "with open(f\"./COT_Pred/gpt4_{start}_{end}_cot_pred.json\", 'w') as f:\n",
    "    json.dump(final_json, f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
