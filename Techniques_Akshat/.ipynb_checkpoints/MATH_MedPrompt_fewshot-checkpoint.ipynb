{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b536bc63-a199-4c78-b876-8dae2e41e166",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import json \n",
    "import regex\n",
    "import random\n",
    "import pickle \n",
    "import re\n",
    "import sys\n",
    "import numpy as np\n",
    "from tqdm import tqdm, trange\n",
    "import pandas as pd\n",
    "from math import *\n",
    "import sys\n",
    "import openai\n",
    "from openai.error import RateLimitError\n",
    "from func_timeout import func_timeout, FunctionTimedOut\n",
    "import argparse\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c443783b-80d1-494f-9e50-8375a44a87ee",
   "metadata": {},
   "source": [
    "## Getting K nearest neighbours for each of the test questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655b0a23-9ef0-4dad-a487-b2d7271bcc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pickle(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        ll = pickle.load(f)\n",
    "        \n",
    "    return ll\n",
    "\n",
    "def write_pickle(path, ll):\n",
    "    with open(path, 'wb') as f:\n",
    "        pickle.dump(ll, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e07e99-f953-4329-8ac7-222394eb303c",
   "metadata": {},
   "outputs": [],
   "source": [
    "MATH_train = read_pickle(\"MATH_embed_train.pkl\")\n",
    "MATH_test = read_pickle(\"MATH_embed_test.pkl\")\n",
    "\n",
    "MATH_train = torch.tensor(MATH_train)\n",
    "MATH_test = torch.tensor(MATH_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bdc214-cd37-431c-b1d2-e609074fcf0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "euc_dist = torch.cdist(MATH_test, MATH_train, p=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9348ea46-11d0-45a5-ae55-8663f2d4f725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Three nearest neighbor for each question in test dataset\n",
    "knn = {}\n",
    "for i in trange(3744):\n",
    "    nn = [j[0] for j in sorted(list(enumerate(euc_dist[i])), key= lambda x: x[1])[:3]]\n",
    "    knn[i+8737] = nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bec9bc-7411-4ff2-8f42-6284a43670ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_pickle(\"knn_new.pkl\", knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1704096c-0738-4a73-844f-42ebc5e69ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"knn_new.pkl\", 'rb') as f:\n",
    "    knn = pickle.load(f)\n",
    "    \n",
    "with open(\"./COT_Pred/gpt4_cot_final_pred.json\",\"r\") as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a63933-bac4-4168-8e9a-dfd37326ce41",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MATH_MedPrompt:\n",
    "    def __init__(self, base, version, key, lm, method, backend_args, quota_args, **kwargs):\n",
    "        self.lm = lm\n",
    "        self.method = method  # step\n",
    "        self.backend = backend_args['name']  # openai\n",
    "        \n",
    "        if self.backend == 'openai':\n",
    "            openai.api_type = \"azure\"\n",
    "            openai.api_base = base\n",
    "            openai.api_version = version\n",
    "            openai.api_key = key\n",
    "    \n",
    "        self.top_p = backend_args['top_p']\n",
    "        self.temp = backend_args['temp']\n",
    "        self.max_token = backend_args['max_token']\n",
    "        self.presence_penalty = backend_args['presence_penalty']        \n",
    "        \n",
    "        self.max_iter_per_instance = quota_args['max_iter_per_instance']\n",
    "\n",
    "        \n",
    "        self.history = []\n",
    "        self.strategy = None\n",
    "\n",
    "        # openai api\n",
    "        self.n_prompt_token = 0\n",
    "        self.n_sample_token = 0\n",
    "        self.messages = []\n",
    "    \n",
    "    def call_openai_api(self, messages, stop, lm=None, top_p=None):\n",
    "        n_try = 10\n",
    "        while n_try > 0:\n",
    "            try:\n",
    "                time.sleep(1)\n",
    "                response = func_timeout(90, \n",
    "                    openai.ChatCompletion.create,\n",
    "                    kwargs={\n",
    "                        \"engine\": self.lm if lm is None else lm,\n",
    "                        \"messages\": messages,\n",
    "                        \"top_p\": self.top_p if top_p is None else top_p,\n",
    "                        \"temperature\": self.temp,\n",
    "                        \"max_tokens\": self.max_token,\n",
    "                        \"presence_penalty\": self.presence_penalty,\n",
    "                        \"stop\": stop,\n",
    "                    }\n",
    "                )\n",
    "                break\n",
    "            except FunctionTimedOut:\n",
    "                print('[LOG] OpenAI API call timeout')\n",
    "                n_try -= 1\n",
    "                if n_try == 0:\n",
    "                    raise Exception('Failed 10 retries.')\n",
    "                continue\n",
    "            except Exception as e:\n",
    "                #print('[LOG]', e)\n",
    "                time.sleep(15)\n",
    "                n_try -= 1\n",
    "                if n_try == 0:\n",
    "                    raise Exception('Failed 10 retries.')\n",
    "                continue\n",
    "        return response\n",
    "    \n",
    "    def call_lm(self, prompt, add_response=True, stop=None, lm=None, top_p=None):\n",
    "        \n",
    "        self.messages.append({'role': 'user', 'content': prompt})\n",
    "        #self.messages = [{'role': 'user', 'content': prompt}]\n",
    "        response = self.call_openai_api(self.messages, stop, lm=lm, top_p=top_p)\n",
    "        if add_response: self.messages.append(response['choices'][0]['message'])\n",
    "        self.n_prompt_token += response['usage']['prompt_tokens']\n",
    "        self.n_sample_token += response['usage']['completion_tokens']\n",
    "        return response['choices'][0]['message']['content']\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1200478-4c6f-4d39-a614-c55c698cefb8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Using chain of thought of nearest neighbours as fewshot examples to get the 10 fewshot-COT response for test question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce86ef28-4af1-4ea7-9f23-47774a48a599",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fewshot_cot_prompt(key):\n",
    "    prompt = \"<Examples>\\n\"\n",
    "    for i in knn[key]:\n",
    "        p = \"Problem - \"+data[i]['problem']+\"\\nSolution - Let's think step by step : \\n\"+data[i]['CoT']+\"\\nFinal answer - \"+data[i]['final_answer']+\"\\n\"+20*\"*\"+\"\\n\"\n",
    "        prompt+=p\n",
    "    prompt+=\"<End of Examples>\\n\\n\"\n",
    "    prompt+=\"Problem - \"+data[key]['problem']+\"\\nSolution - Let's think step by step : \\n\"\n",
    "    return prompt\n",
    "\n",
    "\n",
    "def run_fewshot_cot(fs_prompt):\n",
    "    response = []\n",
    "    for i in range(10):\n",
    "        math = MATH_MedPrompt(base, version, key, \"gpt-4-turbo\", 'step', backend_args, quota_args)\n",
    "        res = math.call_lm(fs_prompt)\n",
    "        response.append(res),\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae520dc-eb3a-40f3-969b-7808d4faf08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_json = []\n",
    "for i in trange(start, end):\n",
    "    \n",
    "    fs_prompt = fewshot_cot_prompt(i)\n",
    "    res_final = run_fewshot_cot(fs_prompt)\n",
    "    final_json.append({\n",
    "        \"index\": i,\n",
    "        \"problem\": data[i]['problem'],\n",
    "        \"FS_CoT\" : res_final\n",
    "    })\n",
    "    if i%1==0:\n",
    "        with open(f\"./10FS_COT_Pred/gpt4_{start}_{end}_fs_cot_pred.json\", 'w') as f:\n",
    "            json.dump(final_json, f)\n",
    "            \n",
    "with open(f\"./10FS_COT_Pred/gpt4_{start}_{end}_fs_cot_pred.json\", 'w') as f:\n",
    "            json.dump(final_json, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b85f9c0-0e9c-4986-8cbe-ce9e238f237f",
   "metadata": {},
   "source": [
    "## Now using the COT we got from previous step to get the final answer for each of the fewshot examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0b1dd1-c0fe-4b77-9d02-23a01d1a3711",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./10FS_COT_Pred/gpt4_10fs_final.json\") as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f178cc7e-1e1e-45cb-9868-e47f51a2b03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_answer_prompt(prompt_cot):\n",
    "    return prompt_cot+\"\\n\\nGive the final answer in the format, #Final answer : <Final_Answer>(only answer value NO units and no other text)#. Therefore the final answer is:\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dca2c3f-aa96-4bd8-832d-e318e672de3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='argparse')\n",
    "parser.add_argument('--start', type=int, default=0,\n",
    "                    help=\"Starting index\")\n",
    "parser.add_argument('--end', type=int, default=12500,\n",
    "                    help=\"Ending index\")\n",
    "parser.add_argument('--base', type=str, default=12500,\n",
    "                    help=\"api_base\")\n",
    "parser.add_argument('--version', type=str, default=12500,\n",
    "                    help=\"api_version\")\n",
    "parser.add_argument('--key', type=str, default=12500,\n",
    "                    help=\"api_key\")\n",
    "args = parser.parse_args()\n",
    "start = int(args.start)\n",
    "end = int(args.end)\n",
    "base = args.base\n",
    "version = args.version\n",
    "key = args.key\n",
    "\n",
    "backend_args = {\n",
    "        'name': \"openai\",\n",
    "        'top_p': 1,\n",
    "        'temp': 0,\n",
    "        'max_token': 3000,\n",
    "        'presence_penalty': 1.5,\n",
    "    }\n",
    "\n",
    "quota_args = {\n",
    "        'sleep_minutes': 1,\n",
    "        'max_iter_per_instance': 4\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f1d58a-4cd4-41af-ad5a-fbfa3bc12326",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_json = []\n",
    "for i in trange(start, end):\n",
    "    index = data[i][\"index\"]\n",
    "    problem = data[i][\"problem\"]\n",
    "    ans_list = []\n",
    "    for j in range(10):\n",
    "        math = MATH_MedPrompt(base, version, key, \"gpt-4-turbo\", 'step', backend_args, quota_args)\n",
    "        cot = data[i][\"FS_CoT\"][j]\n",
    "        prompt_cot = \"Problem - \"+problem+\"\\nSolution - Let's think step by step :\\n\"+cot\n",
    "        final_prompt = final_answer_prompt(prompt_cot)\n",
    "        res_final = math.call_lm(final_prompt)\n",
    "        ans_list.append(res_final.split(\":\")[-1][:-1])\n",
    "    final_json.append({\n",
    "        \"index\": index,\n",
    "        \"problem\": problem,\n",
    "        \"answer_list\" : ans_list})\n",
    "    if i%1==0:\n",
    "        with open(f\"./10FS_Final_Pred/gpt4_{start}_{end}_fs_cot_pred.json\", 'w') as f:\n",
    "            json.dump(final_json, f)\n",
    "            \n",
    "with open(f\"./10FS_Final_Pred/gpt4_{start}_{end}_fs_cot_pred.json\", 'w') as f:\n",
    "            json.dump(final_json, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5eceb2-6d73-478b-8b44-0d04dda04177",
   "metadata": {},
   "source": [
    "## Out of the 10 final answers for each test question in 10FS_Final_Pred , answer with highest occurrence is chosen as final answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849898a8-d7b6-48d3-b2e6-a903a21d1d2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
