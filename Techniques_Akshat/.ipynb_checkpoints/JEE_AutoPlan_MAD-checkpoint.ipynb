{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8222c8ff-1c66-4843-8caf-e90883227090",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import json \n",
    "import regex\n",
    "import random\n",
    "import pickle \n",
    "import re\n",
    "import sys\n",
    "import argparse\n",
    "import numpy as np\n",
    "import openai\n",
    "from func_timeout import func_timeout, FunctionTimedOut\n",
    "import pandas as pd\n",
    "from tqdm import tqdm, trange\n",
    "from utils import *\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8207f4c-8e75-4ed2-a67e-efb14ee25e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for Multi agent debate\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_base = \"\"\n",
    "openai.api_version = \"\"\n",
    "openai.api_key = \"\"\n",
    "\n",
    "def gpt4(text):\n",
    "    \n",
    "    try:\n",
    "        response = openai.ChatCompletion.create(\n",
    "          engine=\"gpt-4-32k\",\n",
    "          messages= [\n",
    "        {\"role\": \"user\", \"content\": text}\n",
    "    ],\n",
    "          temperature=0.7,\n",
    "          max_tokens=6000,\n",
    "          top_p=1,\n",
    "          frequency_penalty=0,\n",
    "          presence_penalty=0\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as exc:\n",
    "        print(exc)\n",
    "        time.sleep(30)\n",
    "        return gpt4(text)\n",
    "    \n",
    "\n",
    "\n",
    "def get_res_from_other_agents(gpt4_res, get_prompt_for_agent):\n",
    "    \n",
    "    final_prompt = \"These are responses from other agents.\"\n",
    "    agent_c = 1\n",
    "    for i in range(len(gpt4_res)):\n",
    "        if i != get_prompt_for_agent:\n",
    "            final_prompt += f\"\\n Agent{agent_c} :\" + gpt4_res[i] \n",
    "            agent_c += 1\n",
    "    \n",
    "    final_prompt += \"\\n Based on the opinion of other agents , give an updated response\"\n",
    "    return final_prompt\n",
    "\n",
    "\n",
    "def output(init_prompt, no_of_agents):\n",
    "    \n",
    "    gpt4_res = [gpt4(init_prompt) for i in range(no_of_agents)]\n",
    "    \n",
    "    folder_name = f\"{no_of_agents}_Model_multi_agent_output\"\n",
    "\n",
    "    if not os.path.exists(folder_name):\n",
    "        os.makedirs(folder_name)\n",
    "\n",
    "    gpt4_1_file = os.path.join(folder_name, \"gpt4_1.txt\")\n",
    "    \n",
    "    ## Initial prompt\n",
    "    with open(gpt4_1_file, 'w') as file:\n",
    "        file.write(\"Initial prompt >>>>>>>> \"+ init_prompt)\n",
    "        file.write('*'*500)\n",
    "        file.write(\"\\n\\n\")\n",
    "    \n",
    "    for itr in trange(1, 6):\n",
    "        gpt4_input = [get_res_from_other_agents(gpt4_res, i) for i in range(no_of_agents)]\n",
    "\n",
    "        gpt4_res = [gpt4(inp) for inp in gpt4_input]\n",
    "        \n",
    "        with open(gpt4_1_file, 'a') as file:\n",
    "            file.write(\"After iteration >>>>>>>>>>>>>>>> \"+ str(itr))\n",
    "            file.write(\"\\n\")\n",
    "            file.write(gpt4_res[0])\n",
    "            file.write(\"\\n\")\n",
    "            file.write('~'*500)\n",
    "            file.write(\"\\n\")\n",
    "\n",
    "    with open(gpt4_1_file, 'r') as file:\n",
    "        return_text = file.read()\n",
    "    \n",
    "    return gpt4_res[0], return_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337fc460-3942-4836-80b7-1666fefffb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoplan:\n",
    "    def __init__(self, lm, method, backend_args, quota_args, **kwargs):\n",
    "        self.lm = lm\n",
    "        self.method = method  # step\n",
    "        self.backend = backend_args['name']  # openai\n",
    "        \n",
    "        if self.backend == 'openai':\n",
    "            openai.api_type = \"azure\"#quota_args[\"api_type\"]\n",
    "            openai.api_base = quota_args[\"api_base\"]\n",
    "            openai.api_version = quota_args[\"api_version\"]\n",
    "            openai.api_key = quota_args[\"api_key\"]\n",
    "    \n",
    "        self.top_p = backend_args['top_p']\n",
    "        self.temp = backend_args['temp']\n",
    "        self.max_token = backend_args['max_token']\n",
    "        self.presence_penalty = backend_args['presence_penalty']        \n",
    "        \n",
    "        self.max_iter_per_instance = quota_args['max_iter_per_instance']\n",
    "\n",
    "        \n",
    "        self.history = []\n",
    "        self.strategy = None\n",
    "\n",
    "        # openai api\n",
    "        self.n_prompt_token = 0\n",
    "        self.n_sample_token = 0\n",
    "        self.messages = []\n",
    "        \n",
    "    def task_desription(self, sub):\n",
    "        if(sub==\"chem\"):\n",
    "            return '''Solve a Chemistry question answering task'''\n",
    "        elif(sub==\"math\"):\n",
    "            return '''Solve a Mathematics question answering task'''\n",
    "        else:\n",
    "             return '''Solve a Physics question answering task'''         \n",
    "       \n",
    "    def price(self):\n",
    "        price = PRICE[self.lm]\n",
    "        return (self.n_prompt_token * price['prompt'] + self.n_sample_token * price['sample']) / 1000\n",
    "    \n",
    "    \n",
    "    def call_openai_api(self, messages, stop, lm=None, top_p=None):\n",
    "        n_try = 10\n",
    "        while n_try > 0:\n",
    "            try:\n",
    "                #time.sleep(1)\n",
    "                response =  openai.ChatCompletion.create(\n",
    "                       engine=\"gpt-4-turbo\",  # The deployment name you chose when you deployed the ChatGPT or GPT-4 model.\n",
    "                        messages=messages,\n",
    "                        temperature=self.temp,\n",
    "                        max_tokens= self.max_token,\n",
    "                        presence_penalty=self.presence_penalty,\n",
    "                        stop=stop,\n",
    "                    )\n",
    "                \n",
    "                break\n",
    "            except FunctionTimedOut:\n",
    "                print('[LOG] OpenAI API call timeout')\n",
    "                n_try -= 1\n",
    "                if n_try == 0:\n",
    "                    raise Exception('Failed 10 retries.')\n",
    "                continue\n",
    "            except Exception as e:\n",
    "                print('[LOG]', e)\n",
    "                time.sleep(15)\n",
    "                n_try -= 1\n",
    "                if n_try == 0:\n",
    "                    raise Exception('Failed 10 retries.')\n",
    "                continue\n",
    "        return response\n",
    "        \n",
    "    def call_lm(self, prompt, add_response=True, stop=None, lm=None, top_p=None):\n",
    "        \n",
    "        self.messages.append({'role': 'user', 'content': prompt})\n",
    "        response = self.call_openai_api(self.messages, stop, lm=lm, top_p=top_p)\n",
    "        if add_response: self.messages.append(response['choices'][0]['message'])\n",
    "        self.n_prompt_token += response['usage']['prompt_tokens']\n",
    "        self.n_sample_token += response['usage']['completion_tokens']\n",
    "        return response['choices'][0]['message']['content']\n",
    "    \n",
    "    def run(self, data, strategy=None, is_test=False, verbose=False, return_history=False):\n",
    "        questions = []\n",
    "        answers = []\n",
    "        predictions = []\n",
    "        summaries = []\n",
    "        flawed_actions = []\n",
    "        flawed_plans = []\n",
    "        history = ''\n",
    "\n",
    "        \n",
    "        for q_idx in range(len(data)):\n",
    "            self.messages = []\n",
    "            sub = data[q_idx]['subject']\n",
    "            init_msg = self.task_desription(sub)\n",
    "            if 'direct' not in self.method and strategy is not None:\n",
    "                init_msg += \"\\n\\nTask Plan:\\n{}\\n\".format(strategy)\n",
    "            init_msg += '\\n'\n",
    "\n",
    "            question = data[q_idx]['question']\n",
    "            answer = data[q_idx]['gold']\n",
    "            questions.append(question)\n",
    "            answers.append(answer)\n",
    "            \n",
    "            input_msg = init_msg + '\\nQuestion: ' + question + '\\n'\n",
    "            solution, all_res = output(input_msg, 4)\n",
    "            \n",
    "            logger.info(pretty_print('Human', input_msg, verbose))\n",
    "            logger.info(solution)\n",
    "            \n",
    "            if not is_test:\n",
    "                summary_msg = ' The ground truth solution is \"{}\". Summarize the interaction history concisely.'.format(answer)\n",
    "                logger.info(pretty_print('Human', summary_msg, verbose))\n",
    "                summary, all_summary = output(summary_msg, 4)\n",
    "                logger.info(pretty_print('Machine', summary, verbose))\n",
    "                summaries.append(summary)\n",
    "                \n",
    "                if strategy is not None:\n",
    "                    failed_action_msg = 'Identify all flawed parts of the plan (not flawed action). Only the flawed part.'\n",
    "                    logger.info(pretty_print('Human', failed_action_msg, verbose))\n",
    "                    failed_action, all_failed = output(failed_action_msg, 4)\n",
    "                    logger.info(pretty_print('Machine', failed_action, verbose))\n",
    "                    flawed_actions.append(failed_action)\n",
    "                    suggest_rev_msg = 'Suggest revision to the current flawed part of the plan. Only the flawed part.'\n",
    "                    logger.info(pretty_print('Human', suggest_rev_msg, verbose))\n",
    "                    suggest_rev, all_revs = output(suggest_rev_msg, 4)\n",
    "                    logger.info(pretty_print('Machine', suggest_rev, verbose))\n",
    "                    flawed_plans.append(suggest_rev)\n",
    "\n",
    "        to_return = None\n",
    "\n",
    "        if is_test:\n",
    "            to_return = predictions\n",
    "        else:\n",
    "            self.messages = []\n",
    "            final_msg = 'Task Description:\\n' + self.task_desription(sub) + '\\n\\n'\n",
    "            final_msg += 'Current Task Plan:\\n{}\\n\\n'.format(strategy)\n",
    "            final_msg += '=' * 10 + 'Task Experiences Begin' + '=' * 10 + '\\n\\n'\n",
    "\n",
    "            for q_idx in range(len(data)):\n",
    "                question = data[q_idx]['question']\n",
    "                final_msg += 'Job {}: Answering the following question. {}\\nSummary of Job {}:\\n{}\\n'.format(q_idx, question, q_idx, summaries[q_idx])\n",
    "                if strategy is not None:\n",
    "                    final_msg += 'Flaws of Plan in Job {}:\\n{}\\n'.format(q_idx, flawed_actions[q_idx])\n",
    "                    final_msg += 'Suggested Revision of Plan from Job {}:\\n{}\\n'.format(q_idx, flawed_plans[q_idx])\n",
    "\n",
    "            final_msg += '=' * 10 + 'Task Experiences End' + '=' * 10 + '\\n\\n'\n",
    "            final_msg += 'Based on the above {} experience of the task, rewrite the current task plan. The plan should be specific to this question and instead of providing the solution give a specific approach.  \\nNew Task Plan:'.format(len(data))\n",
    "            logger.info(pretty_print('Human', final_msg, verbose))\n",
    "\n",
    "            new_strategy, new_strats = output(final_msg, 4)\n",
    "            logger.info(pretty_print('Machine', new_strategy, verbose))\n",
    "            to_return = new_strategy\n",
    "\n",
    "        self.history.append(history)\n",
    "\n",
    "        if return_history:\n",
    "            to_return = to_return, history\n",
    "            return to_return\n",
    "        return to_return, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6a313b-743e-4514-b593-0e9be7b1ac6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "backend_args = {\n",
    "        'name': \"openai\",\n",
    "        'top_p': 1,\n",
    "        'temp': 0,\n",
    "        'max_token': 3000,\n",
    "        'presence_penalty': 1.5,\n",
    "    }\n",
    "quota_args = {\n",
    "        'sleep_minutes': 1,\n",
    "        'max_iter_per_instance': 4,\n",
    "        \"engine\": open_ai_ids.iloc[args.i]['Deployment'],\n",
    "        \"api_base\": open_ai_ids.iloc[args.i]['Base'],\n",
    "        \"api_version\": open_ai_ids.iloc[args.i]['Version'],\n",
    "        \"api_key\":  open_ai_ids.iloc[args.i]['Key']\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8712c3-62c9-4265-a5e2-957813d8b094",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../dataset/dataset.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "    \n",
    "data_train = data[:360]\n",
    "\n",
    "for batch in trange(start, end):\n",
    "    \n",
    "    autoplan = Autoplan(\"gpt-4-turbo\", 'step', backend_args, quota_args)\n",
    "    \n",
    "    strategy = \"Let's first understand the problem and devise a plan to solve the problem. Then, let's carry out the plan and solve the problem step by step.\"          # Plan and solve prompting..\n",
    "    \n",
    "    new_strategy, history = autoplan.run([data_train[batch]],\n",
    "                                    strategy=strategy,\n",
    "                                    is_test=False,\n",
    "                                    verbose=False,\n",
    "                                    return_history=True)\n",
    "    \n",
    "    data_train[batch]['strategy'] = new_strategy\n",
    "    \n",
    "    with open(f\"./strategies/AutoMAD/strategy_{start}_{end}.json\", 'w') as f:\n",
    "            json.dump(data_train[start:end], f)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
