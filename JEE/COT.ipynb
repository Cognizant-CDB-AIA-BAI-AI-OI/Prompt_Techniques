{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4891acc-1602-486f-b665-1be72809d9ad",
   "metadata": {},
   "source": [
    "## JEE Bench using Chain of Thought."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde792ea-763f-405b-b977-f9310f2a9bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "from tqdm import trange\n",
    "import time\n",
    "import pandas as pd\n",
    "import os\n",
    "from tenacity import (\n",
    "    retry,\n",
    "    stop_after_attempt,\n",
    "    wait_random_exponential,\n",
    ")  # for exponential backoff\n",
    "import openai\n",
    "\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_base = \"\"\n",
    "openai.api_version = \"\"\n",
    "openai.api_key = \"\"\n",
    "\n",
    "with open(\"./data/dataset.json\", 'r') as f:\n",
    "    l = json.load(f)\n",
    "    \n",
    "\n",
    "prompts_dic = {\n",
    "\"MCQ\": \"In this problem, only one option will be correct. Give a detailed solution and end the solution with the final answer.\",\n",
    "\"MCQ(multiple)\": \"In this problem, multiple options can be correct. Give a detailed solution and end the solution with the final answer.\",  \n",
    "\"Integer\": \"In this problem, the final answer will be a non-negative integer. Give a detailed solution and end the solution with the final answer.\",\n",
    "\"Numeric\": \"In this problem, the final will be a numeric value. Give the numerical answer correct upto the 2nd decimal digit. Give a detailed solution and end the solution with the final answer.\"\n",
    "}\n",
    "\n",
    "ans_dic = {\n",
    "\"MCQ\": \"A or B or C or D.\",\n",
    "\"MCQ(multiple)\": \"if correct options are A, B and D give ABD alphabetically.\",  \n",
    "\"Integer\": \"Int number only.\",\n",
    "\"Numeric\": \"Float number only.\"\n",
    "}\n",
    "\n",
    "\n",
    "def get_prompt(question: dict):\n",
    "    \n",
    "    p = prompts_dic[question['type']]\n",
    "    \n",
    "    f_text = f\"\"\"\\n\\nGive final answer as Final_answer: {ans_dic[question['type']]}\"\"\"\n",
    "    \n",
    "    return p + \"\\n\\nProblem: \" + question['question'] + f_text + \"\\n\\nLetâ€™s think step by step\", question['gold']\n",
    "    #                                                              (Chain of thought prompt).\n",
    "\n",
    "\n",
    "@retry(wait=wait_random_exponential(min=1, max=60), stop=stop_after_attempt(6))\n",
    "def output(text):\n",
    "    \n",
    "    response = openai.ChatCompletion.create(\n",
    "      engine=\"gpt-4-32k\",\n",
    "      messages= [\n",
    "        {\"role\": \"user\", \"content\": text}\n",
    "        ],\n",
    "      temperature=0,            # reproducible with temp 0.\n",
    "      max_tokens=3048,\n",
    "      top_p=1,\n",
    "      frequency_penalty=0,\n",
    "      presence_penalty=0\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "df = pd.DataFrame({\n",
    "'description':[],\n",
    "'index':[],\n",
    "'subject':[],\n",
    "'type':[],\n",
    "'question':[], \n",
    "'gold':[],\n",
    "'pred':[]\n",
    "})\n",
    "\n",
    "\n",
    "for i in trange(len(l)):\n",
    "    \n",
    "    try:\n",
    "        q, a =  get_prompt(l[i]) # df.iloc[i]['question'], df.iloc[i]['gold']\n",
    "        res = output(q)\n",
    "        l[i]['pred'] = res \n",
    "\n",
    "        df.loc[len(df)] = (l[i]['description'], l[i]['index'], l[i]['subject'], l[i]['type'], l[i]['question'], l[i]['gold'], l[i]['pred'])\n",
    "\n",
    "        if i% 10 == 0:\n",
    "            df.to_excel('Jee_COT.xlsx', index=False)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Exception {e} at {i}\")\n",
    "        \n",
    "        \n",
    "\n",
    "df.to_excel('./data/Jee_COT_output.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b756c3f5-4839-44ec-96cd-7f940b0836ed",
   "metadata": {},
   "source": [
    "## JEEBench using COT.\n",
    "\n",
    "1. Run COT.py to generate the gpt output for all questions and saves in **Jee_COT.xlsx**.\n",
    "2. Run COT_Scoring.py to manually score the GPT4 generations comparing with GOLD and generate **Jee_COT_Scores.xlsx**.\n",
    "3. Run this notebook to see the scores for each Subject and Category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbd475fb-8831-41df-9c0e-e57ba6ed06e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "Jee_cot_generations = pd.read_excel(\"./output/Jee_COT_output.xlsx\")\n",
    "Scores = pd.read_excel(\"./output/Jee_COT_Scores.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7fb4ff6-803f-463c-bf9d-b62d7e8a0526",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "subject\n",
       "chem    0.420290\n",
       "math    0.211823\n",
       "phy     0.252336\n",
       "Name: Score, dtype: float64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Scores.groupby(['subject'])['Score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca477ab8-786b-4446-b3f9-32435b184f0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type\n",
       "Integer          0.172414\n",
       "MCQ              0.373494\n",
       "MCQ(multiple)    0.329545\n",
       "Numeric          0.221374\n",
       "Name: Score, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Scores.groupby(['type'])['Score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "784dc7e2-6d81-453d-b7eb-96bb407867a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2857142857142857"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Scores['Score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fdfe8e1-275d-4212-a830-7e774f2d2103",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "funsearch",
   "language": "python",
   "name": "funsearch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
