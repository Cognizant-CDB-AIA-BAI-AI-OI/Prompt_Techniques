{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff009df0-62b5-4d50-85e1-38762ec4afca",
   "metadata": {},
   "source": [
    "### MATH with Autogen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c889e3c-1a72-45f4-88b1-509e501cfe2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install autogen \n",
    "# !pip install autogen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e77e717-8007-4108-b636-9ecdaac7fe72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import autogen\n",
    "from autogen.agentchat.contrib.math_user_proxy_agent import MathUserProxyAgent\n",
    "import pandas as pd\n",
    "import time\n",
    "import openai\n",
    "from tqdm import trange, tqdm\n",
    "import json\n",
    "import func_timeout\n",
    "import argparse\n",
    "\n",
    "# setting_names = 'Zero-shot', 'Zero-shot-CoT', 'Few-shot', 'Few-shot-CoT'\n",
    "parser = argparse.ArgumentParser(description='argparse')\n",
    "parser.add_argument('--start', type=int, default=0,\n",
    "                    help=\"Starting index\")\n",
    "parser.add_argument('--end', type=int, default=12500,\n",
    "                    help=\"Ending index\")\n",
    "parser.add_argument('--offset', type=int, default=0, help=\"offset.\")\n",
    "parser.add_argument('--i', type=int, default=0,\n",
    "                    help=\"Ending index\")\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "start = int(args.start)\n",
    "end = int(args.end)\n",
    "offset = int(args.offset)\n",
    "oai_i = int(args.i)\n",
    "\n",
    "df = pd.read_csv(\".data/MATH.csv\")\n",
    "\n",
    "\n",
    "config_list = autogen.config_list_from_json(\n",
    "    f\"OAI_FILES/OAI_CONFIG_LIST_{oai_i}.json\",\n",
    "    filter_dict={\n",
    "        \"model\": {\n",
    "            \"gpt-4-turbo\"\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "def get_history():\n",
    "    string = \"\"\n",
    "    for i in list(mathproxyagent.chat_messages.values())[0]:\n",
    "        role = \"assistant\" if i['role']=='user' else 'user'\n",
    "        string += f\"\\n\\n{role}\\n\\n{i['content']}\\n\\n\"\n",
    "        string += \"--\"*50\n",
    "    return string\n",
    "\n",
    "def write_json(path, l):\n",
    "    with open(path, 'w') as f:\n",
    "        json.dump(l, f)\n",
    "\n",
    "def read_json(path):\n",
    "    with open(path, 'r') as f:\n",
    "        l = json.loads(f.read())\n",
    "    return l\n",
    "\n",
    "# 1. create an AssistantAgent instance named \"assistant\"\n",
    "assistant = autogen.AssistantAgent(\n",
    "    name=\"assistant\", \n",
    "    system_message=\"You are a helpful assistant.\",\n",
    "    llm_config={\n",
    "        \"timeout\": 600,\n",
    "        \"seed\": 42,\n",
    "        \"config_list\": config_list,\n",
    "    }\n",
    ")\n",
    "\n",
    "# 2. create the MathUserProxyAgent instance named \"mathproxyagent\"\n",
    "# By default, the human_input_mode is \"NEVER\", which means the agent will not ask for human input.\n",
    "mathproxyagent = MathUserProxyAgent(\n",
    "    name=\"mathproxyagent\", \n",
    "    human_input_mode=\"NEVER\",\n",
    "    code_execution_config={\"use_docker\": False},\n",
    ")\n",
    "\n",
    "def ans(i):\n",
    "    \n",
    "    try:\n",
    "        math_problem = df.iloc[i]['problem']\n",
    "        mathproxyagent.initiate_chat(assistant, problem=math_problem, silent=True)\n",
    "        pred = get_history()\n",
    "    except:\n",
    "        pred = \"\"\n",
    "    \n",
    "    return pred\n",
    "\n",
    "\n",
    "json_save = read_json(f\"Predictions/gpt4_Autogen_pred_{start}_{end}.json\")\n",
    "print(len(json_save), [j['i'] for j in json_save])\n",
    "#start_ = start + \n",
    "\n",
    "for i in trange(start + offset, end):\n",
    "\n",
    "    try:\n",
    "        pred = func_timeout.func_timeout(600, ans, args=(i, ))\n",
    "    except:\n",
    "        print(\"Time limit exceeded..\")\n",
    "        pred = \"\"\n",
    "    \n",
    "    #pred = ans(i)\n",
    "    math_problem = df.iloc[i]['problem']\n",
    "    \n",
    "    json_save.append({\n",
    "    \"i\" : i,\n",
    "    \"problem\": math_problem,\n",
    "    \"pred\": pred,\n",
    "    \"label\": df.iloc[i]['label'],\n",
    "    \"solution\": df.iloc[i]['solution']\n",
    "    })\n",
    "\n",
    "    if i%2==0:\n",
    "        write_json(f\"Predictions/gpt4_Autogen_pred_{start}_{end}.json\", json_save)\n",
    "    \n",
    "    time.sleep(5)\n",
    "    \n",
    "    \n",
    "write_json(f\"Predictions/gpt4_Autogen_pred_{start}_{end}.json\", json_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138c84b2-5d1f-4f7c-9c12-b67bb36a24ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "047f880b-d733-4ad4-b87d-5b93b9ce0b6b",
   "metadata": {},
   "source": [
    "### Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4014f1-7d40-46d9-93d3-ff01be34964a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "import openai\n",
    "from tqdm import trange, tqdm\n",
    "import json\n",
    "import func_timeout\n",
    "\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_base = \"\"\n",
    "openai.api_version = \"\"\n",
    "openai.api_key = \"\"\n",
    "\n",
    "\n",
    "def gpt4(query, i, counter=0):\n",
    "    \n",
    "    try:\n",
    "        messages = [\n",
    "                       {\"role\": \"system\", \"content\": \"You are a helpful AI assistant.\"},\n",
    "                       {\"role\": \"user\", \"content\": query}\n",
    "                   ]\n",
    "        \n",
    "        response = openai.ChatCompletion.create(\n",
    "            engine=\"gpt-4-turbo\",  # The deployment name you chose when you deployed the ChatGPT or GPT-4 model.\n",
    "            messages=messages,\n",
    "            temperature=0\n",
    "        )\n",
    "        return response['choices'][0]['message']['content'], response['usage']\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"exception {e} at:\" + str(i))\n",
    "        if counter < 10:\n",
    "            time.sleep(15)\n",
    "            return gpt4(query, i, counter + 1)\n",
    "        else:\n",
    "            print(f\"exception {e} at:\" + str(i))\n",
    "            return \"\", {\n",
    "    \"completion_tokens\": 0,\n",
    "    \"prompt_tokens\": 0,\n",
    "    \"total_tokens\": 0\n",
    "}\n",
    "\n",
    "def write_json(path, l):\n",
    "    with open(path, 'w') as f:\n",
    "        json.dump(l, f)\n",
    "        \n",
    "\n",
    "def read_json(path):\n",
    "    with open(path, 'r') as f:\n",
    "        l = json.loads(f.read())\n",
    "    return l\n",
    "\n",
    "dataset = read_json(\"Predictions/Complete_predictions.json\")\n",
    "\n",
    "\n",
    "def get_prompt(pred, label):\n",
    "    \n",
    "    return f\"\"\"Given a Prediction from GPT4 for a MATH Problem and its corresponding Answer(Label)\n",
    "You should return True if both are same, else False.\n",
    "If you are not sure whether they are same or not return False.\n",
    "If Prediction or Label anyone is missing return False.\n",
    "\n",
    "Only return True or False. No explanation or anything.\\n\\nPredictions:{pred}\\n\\nLabel: {label} \"\"\"\n",
    "\n",
    "\n",
    "save_json = []\n",
    "for i in trange(len(dataset)):\n",
    "    \n",
    "    prompt = get_prompt(dataset[i]['pred_label'], dataset[i]['label'])\n",
    "    \n",
    "    res, usage = gpt4(prompt, i, 0)\n",
    "    \n",
    "    save_json.append({\"i\": i, \n",
    "                      \"pred_label\" : dataset[i]['pred_label'], \n",
    "                      \"label\" : dataset[i]['label'], \n",
    "                      \"res\": res, \n",
    "                      \"usage\": usage})\n",
    "    \n",
    "    if i%20==0:\n",
    "        write_json(f\"./output/Autogen_Eval.json\", save_json)\n",
    "    \n",
    "    time.sleep(1)\n",
    "    \n",
    "    \n",
    "write_json(f\"./output/Autogen_Eval.json\", save_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a8bb32-608b-43ce-a6b7-ba7d654c070c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1c1e5658-9da8-44d5-a01f-b5aa79506c34",
   "metadata": {},
   "source": [
    "### Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "206ed407-f077-4451-8905-795a04887132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8213 12286 \n",
      "\n",
      "Accuracy:  0.6684844538499105\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def read_json(path):\n",
    "    with open(path, 'r') as f:\n",
    "        l = json.loads(f.read())\n",
    "    return l\n",
    "\n",
    "\n",
    "e = read_json(\"./output/Autogen_Eval.json\")\n",
    "count = 0\n",
    "for i in e:\n",
    "    count += 1 if i['res'].lower()==\"true\" else 0\n",
    "    \n",
    "print(count, len(e), \"\\n\\nAccuracy: \", count/len(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0b9dff-f62d-4abd-9b7f-56567dab3deb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e09f552-b2d4-4658-a10e-6f18883ec0d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b146a4a-4d04-4ad8-9b46-31b26975f85d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "funsearch",
   "language": "python",
   "name": "funsearch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
